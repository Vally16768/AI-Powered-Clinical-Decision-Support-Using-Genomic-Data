# Genomic AI-Orchestrator — CDSS rule-based over genomic scores

Small FastAPI service that:
- loads precomputed variant scores from `variant_scores.csv`,
- prioritizes variants with a transparent rule-based engine,
- optionally generates a clinician-friendly summary via **Ollama**,
- exposes config & audit endpoints.

## What changed (minimal but important)

- **Robust LLM selection**: pick the most performant candidate that *fits* `LLM_MIN_VRAM_GB`; if none fits, fall back to the **smallest**.
- **CSV validation at startup**: checks required columns.
- **Transparent evidence**: every item includes `extra.evidence` (normalized scores + rules fired), `extra.audit`, and top-level `policy_version`.
- **New endpoints**: `GET /config`, `GET /audit/ping`.

## Run

```bash
# (optional) create venv and install
pip install -r requirements.txt  # or: pip install fastapi uvicorn pandas requests pydantic

# Run API
uvicorn app:app --reload --host 0.0.0.0 --port 8000
```

If you use Ollama locally, ensure it is running and the model(s) are pulled (see `LLM_CANDIDATES`).

## API

### `POST /analyze`

Request
```json
{
  "patient_id": "P001",
  "variants": [
    {"variant_id":"chr17:7579472:C:T", "gene": "TP53"},
    {"variant_id":"chr12:25398284:G:A", "gene": "KRAS"}
  ],
  "ehr": {"age": 71, "sex":"M", "cancer_type":"CRC", "stage":"III"}
}
```

Response (shortened)
```json
{
  "patient_id": "P001",
  "policy_version": "1.0.0",
  "prioritized": [
    {
      "variant": {
        "variant_id": "chr17:7579472:C:T",
        "gene": "TP53",
        "cadd": 28.3,
        "polyphen": "probably_damaging",
        "sift": "damaging",
        "clinvar": "likely_pathogenic",
        "extra": {
          "warnings": [],
          "evidence": {
            "cadd_norm": 0.7075,
            "polyphen_score": 1.0,
            "sift_score": 1.0,
            "clinvar_score": 0.8,
            "rules_fired": ["R1:...", "R2:...", "R3:...", "R4:..."]
          },
          "knowledge": [],
          "audit": {"annotated_at": "...", "scored_at": "...", "policy_version": "1.0.0"}
        }
      },
      "priority_score": 0.81625,
      "priority_label": "HIGH",
      "rationale": "Variant prioritized as HIGH based on: CADD 28.3, PolyPhen probably_damaging, ..."
    }
  ]
}
```

### `POST /llm_summary`

Request
```json
{
  "patient_id": "P001",
  "variants": [ /* reuse objects from /analyze response (top 5–10) */ ],
  "ehr": {"age": 71, "sex":"M", "cancer_type":"CRC", "stage":"III"}
}
```

Response
```json
{
  "patient_id": "P001",
  "model": "qwen2.5:3b-instruct",
  "summary": "Text generated by LLM...",
  "generated_at": "2025-11-05T...Z"
}
```

### `GET /health/llm`
Quick reachability check for Ollama.

### `GET /config`
Non-sensitive config: selected model, candidates, VRAM limits, policy version, etc.

### `GET /audit/ping`
Simple audit heartbeat with versions and timestamp.

## Configuration

Use `.env` or environment variables to tune scoring and LLM:

- `LLM_PROVIDER=OLLAMA`
- `LLM_MIN_VRAM_GB=6.0`
- `LLM_CANDIDATES=["qwen2.5:3b-instruct","phi3:mini","qwen2.5:7b-instruct","llama3:8b-instruct"]`
- `LLM_VRAM_CATALOG={"qwen2.5:3b-instruct":6.0,"phi3:mini":4.0,"qwen2.5:7b-instruct":10.0,"llama3:8b-instruct":14.0}`
- `OLLAMA_URL=http://127.0.0.1:11434`
- `LLM_TIMEOUT_SECONDS=10`
- `VARIANT_SCORES_PATH=./variant_scores.csv`
- `SEND_EHR_TO_LLM=true`
- `CADD_MAX=40`
- `W_CADD=0.45` `W_POLYPHEN=0.25` `W_SIFT=0.10` `W_CLINVAR=0.20`

## Notes

- All logic is deterministic & rule-based; the LLM is optional and only used for text summarization.
- No PHI is logged; responses include lightweight audit metadata.
